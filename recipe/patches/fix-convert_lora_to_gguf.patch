diff --git a/convert_lora_to_gguf.py b/convert_lora_to_gguf.py
index bc68f68a..8c9325a9 100755
--- a/convert_lora_to_gguf.py
+++ b/convert_lora_to_gguf.py
@@ -23,7 +23,7 @@ if 'NO_LOCAL_GGUF' not in os.environ:
 import gguf
 
 # reuse model definitions from convert_hf_to_gguf.py
-from convert_hf_to_gguf import LazyTorchTensor, Model
+from llama_cpp_tools.convert_hf_to_gguf import LazyTorchTensor, Model
 
 logger = logging.getLogger("lora-to-gguf")
 
@@ -266,8 +266,7 @@ def parse_args() -> argparse.Namespace:
 
     return parser.parse_args()
 
-
-if __name__ == '__main__':
+def main():
     args = parse_args()
     logging.basicConfig(level=logging.DEBUG if args.verbose else logging.INFO)
 
@@ -404,3 +403,6 @@ if __name__ == '__main__':
         logger.info("Exporting model...")
         model_instance.write()
         logger.info(f"Model successfully exported to {model_instance.fname_out}")
+
+if __name__ == '__main__':
+    main()
