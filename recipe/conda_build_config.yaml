# This feedstocks builds two sets of packages:
# - libllama, llama.cpp, llama.cpp-tests
# - gguf, llama.cpp-tools
# This helps us avoid mixing the two sets of packages in the same build on PBP.
output_set:
  - llama
  - llama_cpp_tools

libcurl:
  - 8

c_stdlib:
  - sysroot                        # [linux]
  - macosx_deployment_target       # [osx]

c_stdlib_version:
  - 2.28                           # [linux]
  - 12.1                           # [osx]
  - 2022.14                        # [win]

c_compiler:                        # [win]
  - vs2022                         # [win]
cxx_compiler:                      # [win]
  - vs2022                         # [win]

blas_impl:
  - mkl                        # [win or (linux and x86_64)]
  - openblas                   # [linux]
  - accelerate                 # [osx]
  - cublas                     # [ANACONDA_ROCKET_ENABLE_CUDA and (win or (linux and x86_64))]

gpu_variant:
  - none
  - metal                      # [osx]
  - cuda-12                    # [ANACONDA_ROCKET_ENABLE_CUDA and (win or (linux and x86_64))]

cuda_compiler_version:         # [ANACONDA_ROCKET_ENABLE_CUDA and (win or (linux and x86_64))]
  - none                       # [ANACONDA_ROCKET_ENABLE_CUDA and (win or (linux and x86_64))]
  - 12.4                       # [ANACONDA_ROCKET_ENABLE_CUDA and (win or (linux and x86_64))]

cuda_compiler:                 # [ANACONDA_ROCKET_ENABLE_CUDA and (win or (linux and x86_64))]
- cuda-nvcc                    # [ANACONDA_ROCKET_ENABLE_CUDA and (win or (linux and x86_64))]

zip_keys:                      # [ANACONDA_ROCKET_ENABLE_CUDA and (win or (linux and x86_64))]
  -                            # [ANACONDA_ROCKET_ENABLE_CUDA and (win or (linux and x86_64))]
    - gpu_variant              # [ANACONDA_ROCKET_ENABLE_CUDA and (win or (linux and x86_64))]
    - cuda_compiler_version    # [ANACONDA_ROCKET_ENABLE_CUDA and (win or (linux and x86_64))]
