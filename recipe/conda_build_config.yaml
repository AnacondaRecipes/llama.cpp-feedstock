# This feedstocks builds two sets of packages:
# - libllama, llama.cpp, llama.cpp-tests
# - gguf, llama.cpp-tools
# This helps us avoid mixing the two sets of packages in the same build on PBP.
output_set:
  - llama
  - llama_cpp_tools

# NOTE: c_stdlib and c_stdlib_version are intentionally NOT defined here.
# When defined with only Linux/macOS selectors (no Windows value), conda-build
# on Windows tries to find a non-existent c_win-64 package. By not defining
# these, conda-build uses its internal defaults which work correctly on all
# platforms. See pytorch-feedstock and onnxruntime-feedstock for reference.

c_compiler:                        # [win]
  - vs2019                         # [win]
cxx_compiler:                      # [win]
  - vs2019                         # [win]

blas_impl:
  - mkl                        # [win or (linux and x86_64)]
  - openblas                   # [linux]
  - accelerate                 # [osx]
  - cublas                     # [win or linux]

gpu_variant:
  - none
  - metal                      # [osx]
  - cuda-12                    # [win or linux]
  - cuda-13                    # [win or linux]
  - cuda-13                    # [win or linux]

# metal builds now require the MTLBuffer gpuAddress property, introduced in macOS 13.0
# metal builds now require the MTLDataType.bfloat4 data type, introduced in macOS 14.0
# This allows us to build with the latest SDK while still supporting older macOS versions.
OSX_SDK_VER:                   # [osx]
  - 14.5                       # [osx]

cuda_compiler_version:         # [win or linux]
  - none                       # [win or linux]
  - 12.8                       # [win or linux]
  - 13.0                       # [win or linux]
  - 13.1                       # [win or linux]

zip_keys:                      # [win or linux]
  -                            # [win or linux]
    - gpu_variant              # [win or linux]
    - cuda_compiler_version    # [win or linux]