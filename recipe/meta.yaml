{% set name = "llama.cpp" %}
{% set version = "0.0.3131" %}
{% set build_number = 0 %}

package:
  name: {{ name|lower }}
  version: {{ version }}

source:
  url: https://github.com/ggerganov/llama.cpp/archive/b{{ version.split(".")[-1] }}.tar.gz
  sha256: 7efc9f88853aa791dbfcc832d207c270ff209009e03a151571f7709a8052035c
  patches:
    - patches/test_exe_threads.patch      # [linux]
    - patches/mkl.patch                   # [blas_impl == "mkl"]
    - patches/metal_gpu_selection.patch   # [osx]

build:
  # skip_cuda_prefect is set through abs.yaml for use in prefect only
  skip: true # [skip_cuda_prefect and (gpu_variant or "").startswith('cuda')]
  skip: true # [s390x]
  skip: true # [gpu_variant == "cuda-11"]
  # do not mix cublas and mkl/openblas
  skip: true # [((gpu_variant or "").startswith('cuda') and (blas_impl != "cublas")) or (not (gpu_variant or "").startswith('cuda') and (blas_impl == "cublas"))]
  # Use a build number difference to ensure that the GPU
  # variant is slightly preferred by conda's solver, so that it's preferentially
  # installed where the platform supports it.
  number: {{ build_number + 200 }}  # [(gpu_variant or "").startswith('cuda') and (gpu_variant != "cuda-11")]
  number: {{ build_number + 100 }}  # [(gpu_variant == "cuda-11") or (gpu_variant == "metal")]
  number: {{ build_number }}        # [gpu_variant == "none"]
  string: cuda{{ cuda_compiler_version | replace('.', '') }}_h{{ PKG_HASH }}_{{ PKG_BUILDNUM }}  # [(gpu_variant or "").startswith('cuda')]
  string: cpu_{{ blas_impl }}_h{{ PKG_HASH }}_{{ PKG_BUILDNUM }}                                 # [gpu_variant == "none"]
  string: mps_h{{ PKG_HASH }}_{{ PKG_BUILDNUM }}                                                 # [gpu_variant == "metal"]
  missing_dso_whitelist:                                                                         # [s390x or (gpu_variant or "").startswith('cuda')]
    - "**/libcuda.so*"                                                                           # [(gpu_variant or "").startswith('cuda')]
    - '$RPATH/ld64.so.1'  # [s390x]
  
requirements:
  build:
    - {{ compiler('c') }}
    - {{ compiler('cxx') }}
    - {{ compiler('cuda') }}                              # [(gpu_variant or "").startswith('cuda') and (gpu_variant != "cuda-11")]
    - cmake
    - ninja-base
    - pkgconfig
    - patch     # [unix]
    - m2-patch  # [win]
    - llvm-openmp 14.0.6 # [osx]
  host:
    - cudatoolkit      {{ cuda_compiler_version }}        # [gpu_variant == "cuda-11"]
    - cuda-version     {{ cuda_compiler_version }}        # [(gpu_variant or "").startswith('cuda')]
    - cuda-cudart-dev  {{ cuda_compiler_version }}        # [(gpu_variant or "").startswith('cuda') and (gpu_variant != "cuda-11")]
    - libcublas-dev    {{ cuda_compiler_version }}        # [(gpu_variant or "").startswith('cuda') and (gpu_variant != "cuda-11")]
    - cuda-compat      {{ cuda_compiler_version }}        # [(gpu_variant or "").startswith('cuda') and (gpu_variant != "cuda-11") and linux]
    - openblas-devel {{ openblas }}                       # [(not (gpu_variant or "").startswith('cuda')) and blas_impl == "openblas"]
    - mkl-devel {{ mkl }}                                 # [(not (gpu_variant or "").startswith('cuda')) and blas_impl == "mkl"]
    - intel-openmp {{ mkl }}                              # [(not (gpu_variant or "").startswith('cuda')) and blas_impl == "mkl"]
    - llvm-openmp 14.0.6                                  # [osx]
  run:
    - {{ pin_compatible('cudatoolkit', max_pin='x.x') }}  # [gpu_variant == "cuda-11"]
    - {{ pin_compatible('cuda-version', max_pin='x.x') }} # [(gpu_variant or "").startswith('cuda')]
    - {{ pin_compatible('intel-openmp') }}                # [(not (gpu_variant or "").startswith('cuda')) and blas_impl == "mkl"]
    - llvm-openmp                                         # [osx]
    - _openmp_mutex                                       # [linux]
    - __osx >={{ MACOSX_DEPLOYMENT_TARGET|default("10.12") }}  # [osx and x86_64]

test:
  commands:
    - main --help
    - server --help
    - test -f $PREFIX/include/llama.h    # [unix]
    - test -f $PREFIX/bin/main           # [unix]
    - test -f $PREFIX/bin/server         # [unix]
    - test -f $PREFIX/lib/libllama.so    # [linux]
    - test -f $PREFIX/lib/libllama.dylib # [osx]
    - if not exist %PREFIX%/Library/include/llama.h exit 1  # [win]
    - if not exist %PREFIX%/Library/lib/llama.lib exit 1    # [win]
    - if not exist %PREFIX%/Library/bin/llama.dll exit 1    # [win]
    - if not exist %PREFIX%/Library/bin/main.exe exit 1     # [win]
    - if not exist %PREFIX%/Library/bin/server.exe exit 1   # [win]

about:
  home: https://github.com/ggerganov/llama.cpp
  summary: LLM inference in C/C++
  description: |
    Inference of Meta's LLaMA model (and others) in pure C/C++
  license: MIT
  license_family: MIT
  license_file: LICENSE
  dev_url: https://github.com/ggerganov/llama.cpp
  doc_url: https://github.com/ggerganov/llama.cpp

extra:
  recipe-maintainers:
    - sodre
    - cbouss
